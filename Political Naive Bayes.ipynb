{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "from string import punctuation\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "convention_db = sqlite3.connect(\"2020_conventions.db\")\n",
    "convention_cur = convention_db.cursor()\n",
    "# List all tables\n",
    "print(convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'district', 'TEXT', 0, None, 0), (1, 'candidate', 'TEXT', 0, None, 0), (2, 'pull_time', 'DATETIME', 0, None, 0), (3, 'tweet_time', 'DATETIME', 0, None, 0), (4, 'handle', 'TEXT', 0, None, 0), (5, 'is_retweet', 'INTEGER', 0, None, 0), (6, 'tweet_id', 'TEXT', 0, None, 0), (7, 'tweet_text', 'TEXT', 0, None, 0), (8, 'likes', 'INTEGER', 0, None, 0), (9, 'replies', 'INTEGER', 0, None, 0), (10, 'retweets', 'INTEGER', 0, None, 0), (11, 'tweet_ratio', 'REAL', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(convention_cur.execute(\"PRAGMA table_info(conventions);\").fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party \n",
    "    FROM conventions\n",
    "    WHERE party IN ('Republican', 'Democratic');\n",
    "    '''\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    text, party = row\n",
    "    text = text.decode('utf-8') if isinstance(text, bytes) else text\n",
    "    convention_data.append([text, party])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Joe knows the world and the world knows him. He knows that our true strength comes from setting an example that the world wants to follow, a nation that stands with democracy, not dictators. A nation that can inspire and mobilize others to overcome threats like climate change and terrorism, poverty, and disease. But more than anything, what I know about Joe, what I know about Kamala, is that they actually care about every American and that they care deeply about this democracy. They believe that in a democracy, the right to vote is sacred and we should be making it easier for people to cast their ballots, not harder.',\n",
       "  'Democratic'],\n",
       " ['It’s our honor to be in the company of great, great champions?',\n",
       "  'Republican'],\n",
       " ['Joe Biden is that kind of leader. I created the Joyful Heart Foundation to help survivors heal and to change the way our society response to sexual violence. The vice president has worked tirelessly by our side to end the backlog of hundreds of thousands of untested rape kits. And our work will continue because testing kits not only makes our country safer, but it sends a vital message to survivors that what happened to them matters.',\n",
       "  'Democratic'],\n",
       " ['Mike earned the trust of the people of his State and became the 50th Governor of Indiana. He delivered the largest state tax cut in Indiana history, expanded school choice, led the country in manufacturing, and helped more Hoosiers get to work than ever before, but he wasn’t through.',\n",
       "  'Republican'],\n",
       " ['I relive that horror in my mind every single day. My hope is that having you relive it with me now, will help shake this country from this nightmare we’re witnessing in our cities and bring about positive, peaceful change. How did we get to this point, where so many young people are callous and indifferent towards human life? This isn’t a video game, where you can commit mayhem and then just hit reset and bring all the characters back to life.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2020 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mauricioespinoza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['One day, I was cleaning golf clubs when a man pulled into the parking lot.',\n",
       "  'Republican'],\n",
       " ['John Lewis had the respect of everybody because he was the one who demonstrated the most courage.',\n",
       "  'Democratic'],\n",
       " ['The Obama-Biden administration secretly launched a surveillance operation on the Trump campaign and silenced the many brave intelligence officials who spoke up against it.',\n",
       "  'Republican'],\n",
       " ['My answer, going high is the only thing that works because when we go low, when we use those same tactics of degrading and dehumanizing others, we just become part of the ugly noise that’s drowning out everything else.',\n",
       "  'Democratic'],\n",
       " ['I stand here tonight, calling on all Americans to join us.', 'Republican']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "conv_sent_data = []\n",
    "\n",
    "for text, party in convention_data:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        conv_sent_data.append([sentence, party])\n",
    "\n",
    "random.choices(conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I took on the biggest banks and help take down one of the biggest for- profit colleges.',\n",
       "  'Democratic'],\n",
       " ['He’s a Trojan horse with Bernie, AOC, Pelosi, Black Lives Matter, and his party’s entire left wing, just waiting to execute their pro-criminal, anti-police, socialist policies.',\n",
       "  'Republican'],\n",
       " ['Trump’s pledge to the American workers definitely means a lot to me because I wouldn’t be where I’m at today.',\n",
       "  'Republican'],\n",
       " ['The Biden-Harris vision for America leaves no room for people of faith.',\n",
       "  'Republican'],\n",
       " ['I pray God’s blessings on you and your family and may God bless America.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thank', 'Democratic'),\n",
       " ('waiting washington act climate change', 'Democratic'),\n",
       " ('millions working families wondering feed kids worried evicted homes',\n",
       "  'Democratic'),\n",
       " ('yeah', 'Democratic'),\n",
       " ('thank senator', 'Democratic')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clean_conv_sent_data = []\n",
    "\n",
    "for idx, sent_party in enumerate(conv_sent_data):\n",
    "    sentence, party = sent_party\n",
    "    tokens = sentence.split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens if token.strip(punctuation).isalpha()]\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    cleaned_sentence = ' '.join(tokens)\n",
    "    clean_conv_sent_data.append((cleaned_sentence, party))\n",
    "\n",
    "random.choices(clean_conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2239 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    ret_dict = dict()\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token in fw:\n",
    "            ret_dict[token] = True\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words) > 0)\n",
    "assert(conv_features(\"obama was the president\", feature_words) ==\n",
    "       {'obama': True, 'president': True})\n",
    "assert(conv_features(\"some people in america are citizens\", feature_words) ==\n",
    "       {'people': True, 'america': True, \"citizens\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            reproductive = True           Democr : Republ =    229.9 : 1.0\n",
      "                  comité = True           Republ : Democr =    143.9 : 1.0\n",
      "              tecnología = True           Republ : Democr =    142.0 : 1.0\n",
      "               postcards = True           Democr : Republ =     86.6 : 1.0\n",
      "                 leftist = True           Republ : Democr =     75.0 : 1.0\n",
      "           reinstituting = True           Republ : Democr =     73.1 : 1.0\n",
      "                graduada = True           Republ : Democr =     71.2 : 1.0\n",
      "           transparencia = True           Republ : Democr =     71.2 : 1.0\n",
      "               polluters = True           Democr : Republ =     65.2 : 1.0\n",
      "             duplicative = True           Republ : Democr =     58.0 : 1.0\n",
      "                illegals = True           Republ : Democr =     50.5 : 1.0\n",
      "              canvassers = True           Democr : Republ =     50.0 : 1.0\n",
      "                 canvass = True           Democr : Republ =     49.2 : 1.0\n",
      "          representantes = True           Republ : Democr =     48.0 : 1.0\n",
      "              wealthiest = True           Democr : Republ =     41.4 : 1.0\n",
      "                votantes = True           Republ : Democr =     39.2 : 1.0\n",
      "                leftists = True           Republ : Democr =     37.3 : 1.0\n",
      "                 livable = True           Democr : Republ =     35.8 : 1.0\n",
      "               privatize = True           Democr : Republ =     35.4 : 1.0\n",
      "                 richest = True           Democr : Republ =     32.8 : 1.0\n",
      "                informes = True           Republ : Democr =     31.3 : 1.0\n",
      "                 cruelly = True           Democr : Republ =     30.9 : 1.0\n",
      "                  aliens = True           Republ : Democr =     30.0 : 1.0\n",
      "             streamlines = True           Republ : Democr =     29.7 : 1.0\n",
      "                 amnesty = True           Republ : Democr =     29.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "My naive bayes classifier achieved an accuracy of 48%, which is worse than random guessing but has lots of room for improvement in distinguishing Democratic and Republican tweets from 2020. The most informative features reveal clear ideological divides:\n",
    "Democratic Tweets: Emphasize social justice (reproductive, livable, cruelly), environmental concerns (polluters), and economic equity (wealthiest, richest). Terms like canvass and postcards highlight grassroots efforts, likely adapted for the COVID-19 context (e.g., mail-based voter outreach).\n",
    "\n",
    "Republican Tweets: Focus on immigration (illegals, aliens, amnesty), anti-leftist rhetoric (leftist, leftists), and government efficiency (duplicative, streamlines). The presence of Spanish words (comité, tecnología, votantes) suggests targeted outreach to Hispanic voters, a key strategy in 2020.\n",
    "\n",
    "The low accuracy is primarily due to a preprocessing mismatch: feature_words were built from cleaned data (lowercase, no punctuation, no stopwords), but convention_data contains raw tweets, leading to missed feature matches for instance healthcare and Healthcare may not be matched. Additionally, noise in the data (e.g., URLs, mentions, and terms like “rt”) and a large feature set (1246 features) may contribute to sparsity and overfitting. The Spanish-language features are interesting but might overfit to a small subset of tweets since the dataset is mostly English.\n",
    "\n",
    "\n",
    "Note: I had originally made the mistake of using the congressional_data.db for training and had a 62% accuracy before realizing my mistake. Once that mistake was made I swapped the variables to match the tables from the correct db and my accuracy dropped by 14%, I wonder why if fit better with the other database, Anywho, just found that interesting. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "congressional_data = []\n",
    "\n",
    "for candidate, party, tweet_text in results:\n",
    "    tweet_text = tweet_text.decode('utf-8') if isinstance(tweet_text, bytes) else tweet_text\n",
    "    congressional_data.append([tweet_text, party])\n",
    "\n",
    "clean_congressional_data = []\n",
    "\n",
    "for text, party in congressional_data:\n",
    "    tokens = text.split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens if token.strip(punctuation).isalpha()]\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    clean_congressional_data.append((cleaned_text, party))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(clean_congressional_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide help putting lives line\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: make even greater kag\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: cavs tie series repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close raised toward match right whoot majors room help us get\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period plan expand offshore drilling opened public days march share oppose proposed program directly trump administration comments made email mail\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated years eastside commitment amp saluted community leaders last awards dinner\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(clean_congressional_data)\n",
    "\n",
    "for idx, tp in enumerate(clean_congressional_data):\n",
    "    tweet, party = tp    \n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Actual vs. Estimated):\n",
      "True \\ Predicted | Democratic | Republican\n",
      "Democratic       | 998        | 4726\n",
      "Republican       | 694        | 3584\n",
      "\n",
      "Accuracy on 10002 scored tweets: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Confusion Matrix (Actual vs. Estimated):\")\n",
    "print(\"True \\\\ Predicted | Democratic | Republican\")\n",
    "print(f\"Democratic       | {results['Democratic']['Democratic']}        | {results['Democratic']['Republican']}\")\n",
    "print(f\"Republican       | {results['Republican']['Democratic']}        | {results['Republican']['Republican']}\")\n",
    "\n",
    "correct = results['Democratic']['Democratic'] + results['Republican']['Republican']\n",
    "total = sum(sum(results[p].values()) for p in parties)\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "print(f\"\\nAccuracy on {total} scored tweets: {accuracy:.2f}\")\n",
    "\n",
    "cong_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "The classifier, trained on 2020 convention speeches, scored a 46% accuracy on 10,002 congressional tweets from 2018, as shown in the confusion matrix. It correctly classified 998 of 5,724 Democratic tweets but misclassified 4,726 as Republican, indicating a strong bias toward the Republican label. For Republican tweets, it correctly identified 3,584 of 4,278, performing better at 84% precision, though 694 were mislabeled as Democratic. The low accuracy, below a 50% random baseline, stems from the mismatch between formal speeches and informal tweets, compounded by the temporal gap between 2020 and 2018 political contexts. The classifier likely overfits to Republican speech patterns, such as deregulation themes, while struggling with overlapping Democratic terms. This highlights the difficulty of cross-domain classification and suggests retraining with a mixed dataset or refining features for tweets. Would you like to adjust the feature set or retrain with different data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
